{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oIhBI4P_n0gb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9GOl6XXM7VkK"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NLtIPqfA7YH8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CzIhtwYM7ZVF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "44GS4wMs7d5W"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9unupOLr73Mi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cr_HXCWW8nOr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-3kShQzQ8rKA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "i6_0lGzp8xfE"
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "lUj71tBG80pA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "R2HJLhgc82qX"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "j8GmZ558-kRm"
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "df[\"sentiment\"] = encoder.fit_transform(df[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "FSArgmlK-nGN"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49582 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      One of the other reviewers has mentioned that ...          1\n",
       "1      A wonderful little production. <br /><br />The...          1\n",
       "2      I thought this was a wonderful way to spend ti...          1\n",
       "3      Basically there's a family where a little boy ...          0\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...          1\n",
       "...                                                  ...        ...\n",
       "49995  I thought this movie did a down right good job...          1\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...          0\n",
       "49997  I am a Catholic taught in parochial elementary...          0\n",
       "49998  I'm going to have to disagree with the previou...          0\n",
       "49999  No one expects the Star Trek movies to be high...          0\n",
       "\n",
       "[49582 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "sH5spJwYBtBP"
   },
   "outputs": [],
   "source": [
    "X = df[\"review\"]\n",
    "y = df[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "qfJMG9N3KF69"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "6uC8x6HbU9bT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "8dDmab1fjZES"
   },
   "outputs": [],
   "source": [
    "# Tokenization, Lowercasing, Removing Stop Words, Special Characters, and Numbers\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lowercased_tokens = [token.lower() for token in tokens]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in lowercased_tokens if token not in stop_words]\n",
    "    filtered_tokens = [token for token in filtered_tokens if token.isalpha()]\n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "k9TCXVOtjaPu"
   },
   "outputs": [],
   "source": [
    "df['processed_reviews'] = df['review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "v_RcRzrCjn4T"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one reviewers mentioned watching oz episode ho...\n",
       "1        wonderful little production br br filming tech...\n",
       "2        thought wonderful way spend time hot summer we...\n",
       "3        basically family little boy jake thinks zombie...\n",
       "4        petter mattei love time money visually stunnin...\n",
       "                               ...                        \n",
       "49995    thought movie right good job creative original...\n",
       "49996    bad plot bad dialogue bad acting idiotic direc...\n",
       "49997    catholic taught parochial elementary schools n...\n",
       "49998    going disagree previous comment side maltin on...\n",
       "49999    one expects star trek movies high art fans exp...\n",
       "Name: processed_reviews, Length: 49582, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"processed_reviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Wdc7inkalmiX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "h5zs2MpkCys1"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Ywc9ItBslwy0"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['processed_reviews'], df['sentiment'], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "8wdle6lyXvbw"
   },
   "outputs": [],
   "source": [
    "# Use CountVectorizer to convert text data into a bag-of-words representation\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "PLdhbf_sRAik"
   },
   "outputs": [],
   "source": [
    "# Define classifiers\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    SVC(),\n",
    "    KNeighborsClassifier(),\n",
    "    MultinomialNB(),\n",
    "    GradientBoostingClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y_ZT7NSDQxfv",
    "outputId": "52a29019-f27b-4a94-974c-1945f3877ca9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TSA\\anaconda3\\envs\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier: LogisticRegression\n",
      "Accuracy: 0.88\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.88      5033\n",
      "           1       0.86      0.89      0.88      4884\n",
      "\n",
      "    accuracy                           0.88      9917\n",
      "   macro avg       0.88      0.88      0.88      9917\n",
      "weighted avg       0.88      0.88      0.88      9917\n",
      "\n",
      "\n",
      "Classifier: DecisionTreeClassifier\n",
      "Accuracy: 0.73\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73      5033\n",
      "           1       0.72      0.74      0.73      4884\n",
      "\n",
      "    accuracy                           0.73      9917\n",
      "   macro avg       0.73      0.73      0.73      9917\n",
      "weighted avg       0.73      0.73      0.73      9917\n",
      "\n",
      "\n",
      "Classifier: RandomForestClassifier\n",
      "Accuracy: 0.85\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85      5033\n",
      "           1       0.84      0.86      0.85      4884\n",
      "\n",
      "    accuracy                           0.85      9917\n",
      "   macro avg       0.85      0.85      0.85      9917\n",
      "weighted avg       0.85      0.85      0.85      9917\n",
      "\n",
      "\n",
      "Classifier: SVC\n",
      "Accuracy: 0.88\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87      5033\n",
      "           1       0.85      0.90      0.88      4884\n",
      "\n",
      "    accuracy                           0.88      9917\n",
      "   macro avg       0.88      0.88      0.88      9917\n",
      "weighted avg       0.88      0.88      0.88      9917\n",
      "\n",
      "\n",
      "Classifier: KNeighborsClassifier\n",
      "Accuracy: 0.60\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.70      0.64      5033\n",
      "           1       0.61      0.49      0.55      4884\n",
      "\n",
      "    accuracy                           0.60      9917\n",
      "   macro avg       0.60      0.59      0.59      9917\n",
      "weighted avg       0.60      0.60      0.59      9917\n",
      "\n",
      "\n",
      "Classifier: MultinomialNB\n",
      "Accuracy: 0.86\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86      5033\n",
      "           1       0.87      0.84      0.86      4884\n",
      "\n",
      "    accuracy                           0.86      9917\n",
      "   macro avg       0.86      0.86      0.86      9917\n",
      "weighted avg       0.86      0.86      0.86      9917\n",
      "\n",
      "\n",
      "Classifier: GradientBoostingClassifier\n",
      "Accuracy: 0.81\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.74      0.79      5033\n",
      "           1       0.77      0.87      0.81      4884\n",
      "\n",
      "    accuracy                           0.81      9917\n",
      "   macro avg       0.81      0.81      0.80      9917\n",
      "weighted avg       0.81      0.81      0.80      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through classifiers\n",
    "for classifier in classifiers:\n",
    "    # If using text data, create a pipeline with a vectorizer\n",
    "    if 'Vectorizer' in classifier.__class__.__name__:\n",
    "        model = Pipeline([('vectorizer', classifier), ('classifier', classifier)])\n",
    "    else:\n",
    "        model = classifier\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_bow, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    predictions = model.predict(X_test_bow)\n",
    "\n",
    "    # Evaluate the performance\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"\\nClassifier: {classifier.__class__.__name__}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "YmqbhYY3GslS"
   },
   "outputs": [],
   "source": [
    "# Convert text data to TF-IDF features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "e_RSzr9GUgAY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier: LogisticRegression\n",
      "Accuracy: 0.86\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86      5033\n",
      "           1       0.84      0.88      0.86      4884\n",
      "\n",
      "    accuracy                           0.86      9917\n",
      "   macro avg       0.86      0.86      0.86      9917\n",
      "weighted avg       0.86      0.86      0.86      9917\n",
      "\n",
      "\n",
      "Classifier: DecisionTreeClassifier\n",
      "Accuracy: 0.71\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.71      5033\n",
      "           1       0.70      0.72      0.71      4884\n",
      "\n",
      "    accuracy                           0.71      9917\n",
      "   macro avg       0.71      0.71      0.71      9917\n",
      "weighted avg       0.71      0.71      0.71      9917\n",
      "\n",
      "\n",
      "Classifier: RandomForestClassifier\n",
      "Accuracy: 0.83\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      5033\n",
      "           1       0.82      0.84      0.83      4884\n",
      "\n",
      "    accuracy                           0.83      9917\n",
      "   macro avg       0.83      0.83      0.83      9917\n",
      "weighted avg       0.83      0.83      0.83      9917\n",
      "\n",
      "\n",
      "Classifier: SVC\n",
      "Accuracy: 0.86\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86      5033\n",
      "           1       0.84      0.88      0.86      4884\n",
      "\n",
      "    accuracy                           0.86      9917\n",
      "   macro avg       0.86      0.86      0.86      9917\n",
      "weighted avg       0.86      0.86      0.86      9917\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TSA\\anaconda3\\envs\\myenv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\TSA\\anaconda3\\envs\\myenv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\TSA\\anaconda3\\envs\\myenv\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\TSA\\anaconda3\\envs\\myenv\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\TSA\\anaconda3\\envs\\myenv\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier: KNeighborsClassifier\n",
      "Accuracy: 0.71\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.70      0.71      5033\n",
      "           1       0.70      0.71      0.71      4884\n",
      "\n",
      "    accuracy                           0.71      9917\n",
      "   macro avg       0.71      0.71      0.71      9917\n",
      "weighted avg       0.71      0.71      0.71      9917\n",
      "\n",
      "\n",
      "Classifier: MultinomialNB\n",
      "Accuracy: 0.84\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.83      5033\n",
      "           1       0.82      0.86      0.84      4884\n",
      "\n",
      "    accuracy                           0.84      9917\n",
      "   macro avg       0.84      0.84      0.84      9917\n",
      "weighted avg       0.84      0.84      0.84      9917\n",
      "\n",
      "\n",
      "Classifier: GradientBoostingClassifier\n",
      "Accuracy: 0.80\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.74      0.79      5033\n",
      "           1       0.76      0.87      0.81      4884\n",
      "\n",
      "    accuracy                           0.80      9917\n",
      "   macro avg       0.81      0.80      0.80      9917\n",
      "weighted avg       0.81      0.80      0.80      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through classifiers\n",
    "for classifier in classifiers:\n",
    "    # If using text data, create a pipeline with a vectorizer\n",
    "    if 'Vectorizer' in classifier.__class__.__name__:\n",
    "        model = Pipeline([('vectorizer', classifier), ('classifier', classifier)])\n",
    "    else:\n",
    "        model = classifier\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    predictions = model.predict(X_test_tfidf)\n",
    "\n",
    "    # Evaluate the performance\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"\\nClassifier: {classifier.__class__.__name__}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qw-VG_cVUsqw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
